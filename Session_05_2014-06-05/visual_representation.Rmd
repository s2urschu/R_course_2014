# Sitzung 05
## Appetizer: Wordclouds using R

Wir lesen XML-Dateien aus dem Tüba-D/Z-Korpus ein und extrahieren *Lemmata* und laufende *Wortformen*:
```{r reading_XML, highlight = TRUE, results = 'hide', echo = TRUE, cache = TRUE}
library(XML)

tokens <- NULL

xmlEventParse(
  "../data/t_990505_47.xml", 
  handlers = list(
    't' = function(name, attr) {
      tokens <<- c(tokens, attr['word'])
      ## types,
      ## morphology
      }
    ),
  addContext = FALSE
  )

#names(tokens) <- NULL
tokens <- unname(tokens)
```

```{r wordcloud, highlight = TRUE, echo = TRUE, cache = TRUE}
library(tm)
library(wordcloud)
myCorpus = Corpus(VectorSource(tokens))
myCorpus = tm_map(myCorpus, removePunctuation)
myCorpus = tm_map(myCorpus, removeNumbers)
myCorpus = tm_map(myCorpus, removeWords,
                  c(stopwords("german"), "die", "der", "das"))

myDTM = TermDocumentMatrix(myCorpus,
                           control = list(minWordLength = 1))

m = as.matrix(myDTM)
sorted.matrix <- sort(rowSums(m), decreasing = TRUE)

wordcloud(names(sorted.matrix), sorted.matrix, scale=c(4,0.5),
          min.freq = 1, max.words = 20,
          colors = brewer.pal(8, "Dark2"))
```

## Dataframes anlegen

    Wortart    TokenFrequenz  TypenFrequenz	Klasse
    ADJ	     421		271		offen
    ADV	     337		103		offen
    N	     1411		735		offen
    KONJ	     458		18		geschlossen
    PRAEP	     455		37		geschlossen

    x <- data.frame(Wortart, TokenFrequenz, ...)

    str(x) # Was ist mit Factors passiert?

    x <- data.frame(Wortart, TokenFrequenz, ..., row.names=Wortart)


## Frames speichern:
  
    write.table(x, file=, sep='\t') # Siehe `?write.table`

## Frames einlesen:

    # Mit Standardwerten spielen, `?read.table`
    # x <- read.table(file='', header=(TRUE|FALSE), row.names = 1)

## Frameelemente ansprechen:

    x$TokenFrequenz
    x$Klasse

    attach(x)
    TokenFrequenz
    Klasse

    x[2, 3] # 2. Zeile, 3. Spalte
    x[2,] # 2. Zeile
    x[,3] # 3. Spalte
    x[2] #!!! 2. Spalte

    x[2:3, 3:4] # Subset of a frame

## Bedingte Auswahl:
    x$Klasse == 'offen'
    x[x$Klasse == 'offen',]

    ? какой еще вариант записи есть
    x[x[,4] == 'offen',]

    x[x$Klasse == 'offen',][x$TypenFrequenz > 150,]

    # Selbst erklären:
    x[x$Klasse == 'offen',][x$TypenFrequenz < 500,]
    x[x$Klasse == 'geschlossen',][x$TypenFrequenz > 100,]


    # Was macht der folgende Befehl?
    x[,3][which(x[,2] > 450)]


## `subset`

    subset(x, x$Klasse == 'geschlossen')

    # Leeres Ergebnis
    subset(x, x$Klasse == 'offen' & x$TypenFrequenz < 100)

    subset(x, x$Klasse == 'offen' & x$TypenFrequenz < 200)

    subset(x, x$Klasse == 'offen' | x$Wortart == 'KONJ')

    # nicht zulässig
    subset(x, x$Klasse == 'offen' | x$Wortart == ('KONJ' | 'PRAEP'))
    # besser so
    subset(x, x$Klasse == 'offen' | x$Wortart %in% c('KONJ', 'PRAEP'))

    # seblständig
    subset(x, x$Wortart %in% c('N', 'ADJ'))

## `fix()`: Eingebauter Editor

    fix(x)

## Sortieren:

    vec <- c(1,5,2,3)
    sort(vec) # => [1] 1 2 3 5
    order(vec) # => [1] 1 3 4 2
    # ??? Was macht die Funktion `order()`

    x[order(x$TypenFrequenz),]
    x[order(-x$TypenFrequenz),]

## Random Sampling: `sample()`

    x[sample(length(x$Klasse)),] # Mehrmals ausprobieren.

## Deskriptiv statistics
```{r}
library(moments)

random.vector <- rnorm(100)
str(random.vector)
summary(random.vector)
mean(random.vector)
median(random.vector)
quantile(random.vector, c(0.25, 0.5, 0.75))
sd(random.vector)
var(random.vector)
mad(random.vector)
skewness(random.vector)
kurtosis(random.vector)
    
```

## Graphische Darstellung
